{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext, Row\n",
    "import pyspark.sql.functions as sqlf\n",
    "\n",
    "# Create a Spark Context\n",
    "sc = SparkContext.getOrCreate();\n",
    "sqlc = SQLContext(sc)\n",
    "\n",
    "years = range(2000, 2001)\n",
    "\n",
    "for year in years:\n",
    "    txtfile = sc.textFile('../madhu95/data/%s.csv' % year)\n",
    "    # RDD: split attribute values using commas\n",
    "    data = txtfile.map(lambda x: x.split(','))\n",
    "    # RDD:create table\n",
    "    table = data.map(lambda r: Row(station=r[0], date=r[1], ele=r[2], val=int(r[3]), m_flag=r[4], q_flag=r[5], s_flag=r[6], obs_time=r[7]))\n",
    "    #  dataframe\n",
    "    df = sqlc.createDataFrame(table)\n",
    "\n",
    "    # Handle abnomalities missing data\n",
    "    clean_df = df.filter(df['q_flag'] == '')\n",
    "\n",
    "    print(\"\\nYear %s Temerature statistics:\\n\" % year)\n",
    "    \n",
    "\n",
    "    # Max TMAX\n",
    "    res = clean_df.filter(clean_df['ele'] == 'TMAX').groupby().max('val').first()\n",
    "    print('Max TMAX(maximum temperature) value = %.2f degrees Celsius' % (res['max(val)'] / 10.0))\n",
    "\n",
    "    #  Min TMIN\n",
    "    res = clean_df.filter(clean_df['ele'] == 'TMIN').groupby().min('val').first()\n",
    "    print('Min TMIN(Minimum temperature) value = %.2f degrees Celsius' % (res['min(val)'] / 10.0))\n",
    "\n",
    "    # Five hottest weather stations\n",
    "    res = clean_df.filter(clean_df['ele'] == 'TMAX').sort(sqlf.desc('val')).limit(3).collect()\n",
    "    print(\"Top 3 hottest weather stations  in tems of temperature \")\n",
    "    for i in res:\n",
    "        print('Station:%s\\tTemperature:%.2f degrees Celsius' % (i.station, float(i['val']) / 10.0))\n",
    "    # Five coldest weather stations \n",
    "    res = clean_df.filter(clean_df['ele'] == 'TMIN').sort(sqlf.asc('val')).limit(3).collect()\n",
    "    print(\"Top 3 coldest weather stations in terms of temperature\")\n",
    "    for i in res:\n",
    "        print('Station:%s\\tTemperature:%.2f degrees Celsius' % (i.station, float(i['val']) / 10.0))\n",
    "        \n",
    "        \n",
    "\n",
    "# overall statistics\n",
    "txtfile1 = sc.textFile('../madhu95/data/20??.csv')\n",
    "data = txtfile1.map(lambda x: x.split(','))\n",
    "table = data.map(lambda r: Row(station=r[0], date=r[1], ele=r[2], val=int(r[3]), m_flag=r[4], q_flag=r[5], s_flag=r[6], obs_time=r[7]))\n",
    "df = sqlc.createDataFrame(table)\n",
    "clean_df = df.filter(df['q_flag'] == '')\n",
    "\n",
    "# hottest day and weather station\n",
    "res = clean_df.filter(clean_df['ele'] == 'TMAX').sort(sqlf.desc('val')).first()\n",
    "print(\"Hottest station: %s on %s with temperature:%.2f degrees Celsius\" % (res.station, res.date, float(res['val']) / 10.0))\n",
    "\n",
    "# coldest day and weather station\n",
    "res = clean_df.filter(clean_df['ele'] == 'TMIN').sort(sqlf.asc('val')).first()\n",
    "print(\"Coldest Station: %s on %s with temperature:%.2f degrees Celsius\" % (res.station, res.date, float(res['val']) / 10.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
